{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_probability.python.distributions as tfd\n",
    "import tensorflow_probability.python.layers as tfl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/pmarc/PycharmProjects/covid19-forecast-hub-europe/data-truth/JHU/\"\n",
    "cols = [\"cases\"]\n",
    "target_cols = [\"cases\"]\n",
    "input_width = 1\n",
    "label_width = 1\n",
    "shift = 1\n",
    "train_data_pcnt = 70\n",
    "valid_data_pcnt = 20\n",
    "test_data_pcnt = 10\n",
    "epochs = 1000\n",
    "final_model_path = \"Models/Final/\"\n",
    "results_path = \"Models/Results/\"\n",
    "graphs_path = \"Models/Graphs/\"\n",
    "processed_path = \"C:/Users/pmarc/PycharmProjects/covid19-forecast-hub-europe/data-processed/UNED-CovidPredPMA/\"\n",
    "display_images = True\n",
    "save_images = False\n",
    "period = \"weeks\"\n",
    "last_day = \"2021-07-31\"\n",
    "first_day = \"2020-01-23\"\n",
    "# predictions_date_init = \"2021-09-13\"\n",
    "# predictions_date_end = \"2021-09-25\"\n",
    "team_model_name = \"UNED-CovidPredPMA-Poisson\"\n",
    "countries = [\n",
    "    # 'Austria',\n",
    "    # 'Belgium',\n",
    "    # 'Bulgaria',\n",
    "    # 'Croatia',\n",
    "    # 'Cyprus',\n",
    "    # 'Czechia',\n",
    "    # 'Denmark',\n",
    "    # 'Estonia',\n",
    "    # 'Finland',\n",
    "    'France',\n",
    "    'Germany',\n",
    "    # 'Greece',\n",
    "    # 'Hungary',\n",
    "    # 'Iceland',\n",
    "    # 'Ireland',\n",
    "    'Italy',\n",
    "    # 'Latvia',\n",
    "    # 'Liechtenstein',\n",
    "    # 'Lithuania',\n",
    "    # 'Luxembourg',\n",
    "    # 'Malta',\n",
    "    # 'Netherlands',\n",
    "    # 'Norway',\n",
    "    # 'Poland',\n",
    "    # 'Portugal',\n",
    "    # 'Romania',\n",
    "    # 'Slovakia',\n",
    "    # 'Slovenia',\n",
    "    'Spain',\n",
    "    # 'Sweden',\n",
    "    # 'Switzerland',\n",
    "    'United Kingdom'\n",
    "]\n",
    "country_codes = {\n",
    "    'Austria': 'AT',\n",
    "    'Belgium': 'BE',\n",
    "    'Bulgaria': 'BG',\n",
    "    'Croatia': 'HR',\n",
    "    'Cyprus': 'CY',\n",
    "    'Czechia': 'CZ',\n",
    "    'Denmark': 'DK',\n",
    "    'Estonia': 'EE',\n",
    "    'Finland': 'FI',\n",
    "    'France': 'FR',\n",
    "    'Germany': 'DE',\n",
    "    'Greece': 'GR',\n",
    "    'Hungary': 'HU',\n",
    "    'Iceland': 'IS',\n",
    "    'Ireland': 'IE',\n",
    "    'Italy': 'IT',\n",
    "    'Latvia': 'LV',\n",
    "    'Liechtenstein': 'LI',\n",
    "    'Lithuania': 'LT',\n",
    "    'Luxembourg': 'LU',\n",
    "    'Malta': 'MT',\n",
    "    'Netherlands': 'NL',\n",
    "    'Norway': 'NO',\n",
    "    'Poland': 'PL',\n",
    "    'Portugal': 'PT',\n",
    "    'Romania': 'RO',\n",
    "    'Slovakia': 'SK',\n",
    "    'Slovenia': 'SI',\n",
    "    'Spain': 'ES',\n",
    "    'Sweden': 'SE',\n",
    "    'Switzerland': 'CH',\n",
    "    'United Kingdom': 'GB',\n",
    "}\n",
    "quantiles = [\n",
    "    1.00,\n",
    "    2.50,\n",
    "    5.00,\n",
    "    10.0,\n",
    "    15.0,\n",
    "    20.0,\n",
    "    25.0,\n",
    "    30.0,\n",
    "    35.0,\n",
    "    40.0,\n",
    "    45.0,\n",
    "    50.0,\n",
    "    55.0,\n",
    "    60.0,\n",
    "    65.0,\n",
    "    70.0,\n",
    "    75.0,\n",
    "    80.0,\n",
    "    85.0,\n",
    "    90.0,\n",
    "    95.0,\n",
    "    97.5,\n",
    "    99.0]\n",
    "median_quantile_index = 11\n",
    "quantile_50_low_index = 6\n",
    "quantile_50_high_index = 16\n",
    "quantile_95_low_index = 1\n",
    "quantile_95_high_index = 21\n",
    "country = 'Spain'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_truth_data(filepath, filepath_deaths):\n",
    "    df_cases = pd.read_csv(filepath)\n",
    "    df_deaths = pd.read_csv(filepath_deaths)\n",
    "    if country == \"all\":\n",
    "        df_filtered = df_cases\n",
    "        df_deaths_filtered = df_deaths\n",
    "    else:\n",
    "        df_filtered = df_cases[(df_cases[\"location_name\"] == country)]\n",
    "        df_deaths_filtered = df_deaths[(df_deaths[\"location_name\"] == country)]\n",
    "\n",
    "    df_filtered[\"value\"] = df_filtered[\"value\"].where(df_filtered[\"value\"] >= 0, other=-df_filtered[\"value\"], axis=0)\n",
    "    df_deaths_filtered[\"value\"] = df_deaths_filtered[\"value\"].where(df_deaths_filtered[\"value\"] >= 0,\n",
    "                                                                    other=-df_deaths_filtered[\"value\"], axis=0)\n",
    "    df_filtered[\"date\"] = pd.to_datetime(df_filtered[\"date\"])\n",
    "    df_filtered.set_index(df_filtered[\"date\"], inplace=True)\n",
    "    df_deaths_filtered[\"date\"] = pd.to_datetime(df_deaths_filtered[\"date\"])\n",
    "    df_deaths_filtered.set_index(df_deaths_filtered[\"date\"], inplace=True)\n",
    "    df_filtered.drop(\"date\", axis=1, inplace=True)\n",
    "    df_filtered.drop(\"location\", axis=1, inplace=True)\n",
    "    df_filtered.drop(\"location_name\", axis=1, inplace=True)\n",
    "    df_filtered[\"cases\"] = df_filtered[\"value\"]\n",
    "    df_filtered.drop(labels=\"value\", axis=1, inplace=True)\n",
    "    # df_filtered[\"deaths\"] = df_deaths_filtered[\"value\"]\n",
    "    # df_filtered.replace(to_replace='United Kingdom', value='United_Kingdom', inplace=True)\n",
    "\n",
    "    # Include data only after 1th case in a country.\n",
    "    # mask = df_filtered['cases'].cumsum() >= 1\n",
    "\n",
    "    # Get the date that the epidemic starts in a country.\n",
    "    # first_day = df_filtered.index[mask][0]  # - pd.to_timedelta(START_DAYS, 'days')\n",
    "    if first_day is not None:\n",
    "        df_filtered = df_filtered.truncate(before=first_day)\n",
    "    if last_day is not None:\n",
    "        df_filtered = df_filtered.truncate(after=last_day)\n",
    "\n",
    "    if period == \"weeks\":\n",
    "        df_filtered = df_filtered.resample(\"w-sat\", convention=\"end\").sum()\n",
    "\n",
    "    return df_filtered"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def nll(y, distr):\n",
    "    return -distr.log_prob(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_linear_model(model=None, plot_col='cases', plot_model=\"random\", plot_quantile=True,\n",
    "                      image_path=None, x=None, y=None):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    num_days = len(x)\n",
    "\n",
    "    pred_cases_raw = model(x)\n",
    "    mean = pred_cases_raw.mean()\n",
    "    std = pred_cases_raw.stddev()\n",
    "    posterior_quantile = np.percentile(mean, quantiles, axis=-1, interpolation=\"midpoint\")\n",
    "    ax.plot(range(num_days), mean, '--X', color='#ff7f0e', label='Posterior median', lw=3, markersize=6)\n",
    "    if plot_quantile:\n",
    "        ax.plot(range(num_days), mean + 2 * std, color='b', label='50% quantile', alpha=.4, lw=3)\n",
    "        ax.plot(range(num_days), mean - 2 * std, color='b', label='50% quantile', alpha=.4, lw=3)\n",
    "    ax.plot(range(num_days), y[:num_days], '--o', color='k', markersize=6, label='Observed '+plot_col)\n",
    "\n",
    "    ax.xaxis.set_tick_params(rotation=45)\n",
    "    ax.set_title(plot_model + \" set for \" + country + \" \" + plot_col)\n",
    "    ax.set_xlabel('Day', fontsize='large')\n",
    "    ax.set_ylabel(plot_col, fontsize='large')\n",
    "    fontsize = 'large'\n",
    "    ax.legend(loc='upper left', fontsize=fontsize)\n",
    "    ax.axhline(y=0, color='k', linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_images:\n",
    "        plt.savefig(image_path + \"_predictions.png\")\n",
    "    if display_images:\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_cpd(model=None, num_weeks=1, x=None, y=None):\n",
    "    y_hat=model.predict(x)\n",
    "    y_hat_mean = y_hat.mean()\n",
    "    y_hat_std = y_hat.std()\n",
    "    plt.scatter(y_hat, y, alpha=0.3)\n",
    "    # sort_idx=np.argsort(y_hat,axis=0)\n",
    "    plt.plot(y_hat, y_hat + 2 * y_hat_std, linestyle='dashed', c=\"black\")\n",
    "    plt.plot(y_hat, y_hat - 2 * y_hat_std, linestyle='dashed', c=\"black\")\n",
    "    plt.plot(y_hat, y_hat, c=\"black\")\n",
    "    plt.title('Observed vs. Predicted for ' + country + \" and \" + str(num_weeks) + \" predicted weeks\")\n",
    "    plt.xlabel('Predicted average')\n",
    "    plt.ylabel('Observed number')\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_train_history(history, title, image_path):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    if save_images:\n",
    "        plt.savefig(image_path + \"_train_history.png\")\n",
    "    if display_images:\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = read_truth_data(data_path + \"truth_JHU-Incident Cases.csv\",\n",
    "                     data_path + \"truth_JHU-Incident Deaths.csv\", country=country, period=period, last_day=last_day)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_path = \"{0}_{1}_{2}\".format(country, target_cols, datetime.datetime.today().strftime(\"%Y%m%d\"))\n",
    "file_path = \"{0}_{1}\".format(country, datetime.datetime.today().strftime(\"%Y%m%d\"))\n",
    "df_train = df[0:int(len(df) * (train_data_pcnt / 100))]\n",
    "df_valid = df[int(len(df)*(train_data_pcnt/100)):int(len(df)*((train_data_pcnt + valid_data_pcnt)/100))]\n",
    "df_test = df[-int(len(df) * (test_data_pcnt / 100)):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=0  # Indica el salto entre la semana con datos y la semana a predecir: 1 indica un salto de 1 semana,\n",
    "         # por lo tanto, se hará una predicción de 2 semanas después\n",
    "data_train_1_w = np.array(df_train, dtype=np.float32)\n",
    "x_train_1_w = data_train_1_w[:-label_width-shift]\n",
    "y_train_1_w = np.squeeze(data_train_1_w[input_width+shift:])\n",
    "data_valid_1_w = np.array(df_valid, dtype=np.float32)\n",
    "x_valid_1_w = data_valid_1_w[:-label_width-shift]\n",
    "y_valid_1_w = np.squeeze(data_valid_1_w[input_width+shift:])\n",
    "data_test_1_w = np.array(df_test, dtype=np.float32)\n",
    "x_test_1_w = data_test_1_w[:-label_width-shift]\n",
    "y_test_1_w = np.squeeze(data_test_1_w[input_width+shift:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_1_w = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2),\n",
    "        tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[:, :1],\n",
    "                                                    scale=1e-3 + tf.math.softplus(0.05 * t[:, 1:]))),\n",
    "    ])\n",
    "model_lr_1_w.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=nll)\n",
    "result_lr_1_w = model_lr_1_w.fit(x_train_1_w, y_train_1_w, epochs=epochs, validation_data=(x_valid_1_w, y_valid_1_w), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_1_w.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_history(result_lr_1_w, 'Train history loss for ' + country + \" \" +\n",
    "                   datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\"), final_model_path + image_path)\n",
    "\n",
    "train_performance_1_w = model_lr_1_w.evaluate(x_train_1_w, y_train_1_w, verbose=1)\n",
    "val_performance_1_w = model_lr_1_w.evaluate(x_valid_1_w, y_valid_1_w, verbose=1)\n",
    "test_performance_1_w = model_lr_1_w.evaluate(x_test_1_w, y_test_1_w, verbose=1)\n",
    "print(\"Linear Regression NLL on training 1 week: \", train_performance_1_w)\n",
    "print(\"Linear Regression NLL on validation 1 week: \", val_performance_1_w)\n",
    "print(\"Linear Regression NLL on test 1 week: \", test_performance_1_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_linear_model(model_lr_1_w, plot_model=\"train\", plot_col=\"cases\", x=x_train_1_w, y=y_train_1_w,\n",
    "                  image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_1_w, plot_model=\"val\", plot_col=\"cases\", x=x_valid_1_w, y=y_valid_1_w,\n",
    "              image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_1_w, plot_model=\"test\", plot_col=\"cases\", x=x_test_1_w, y=y_test_1_w,\n",
    "              image_path=graphs_path + image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cpd(model_lr_1_w, 1, x_train_1_w, y_train_1_w)\n",
    "plot_cpd(model_lr_1_w, 1, x_valid_1_w, y_valid_1_w)\n",
    "plot_cpd(model_lr_1_w, 1, x_test_1_w, y_test_1_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=1  # Indica el salto entre la semana con datos y la semana a predecir: 1 indica un salto de 1 semana,\n",
    "         # por lo tanto, se hará una predicción de 2 semanas después\n",
    "data_train_2_w = np.array(df_train, dtype=np.float32)\n",
    "x_train_2_w = data_train_2_w[:-label_width-shift]\n",
    "y_train_2_w = np.squeeze(data_train_2_w[input_width+shift:])\n",
    "data_valid_2_w = np.array(df_valid, dtype=np.float32)\n",
    "x_valid_2_w = data_valid_2_w[:-label_width-shift]\n",
    "y_valid_2_w = np.squeeze(data_valid_2_w[input_width+shift:])\n",
    "data_test_2_w = np.array(df_test, dtype=np.float32)\n",
    "x_test_2_w = data_test_2_w[:-label_width-shift]\n",
    "y_test_2_w = np.squeeze(data_test_2_w[input_width+shift:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_2_w = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2),\n",
    "        tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[:, :1],\n",
    "                                                    scale=1e-3 + tf.math.softplus(0.05 * t[:, 1:]))),\n",
    "    ])\n",
    "model_lr_2_w.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=nll)\n",
    "result_lr_2_w = model_lr_2_w.fit(x_train_2_w, y_train_2_w, epochs=epochs, validation_data=(x_valid_2_w, y_valid_2_w), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_2_w.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_history(result_lr_2_w, 'Train history loss for ' + country + \" \" +\n",
    "                   datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\"), final_model_path + image_path)\n",
    "\n",
    "train_performance_2_w = model_lr_2_w.evaluate(x_train_2_w, y_train_2_w, verbose=1)\n",
    "val_performance_2_w = model_lr_2_w.evaluate(x_valid_2_w, y_valid_2_w, verbose=1)\n",
    "test_performance_2_w = model_lr_2_w.evaluate(x_test_2_w, y_test_2_w, verbose=1)\n",
    "print(\"Linear Regression NLL on training 2 weeks: \", train_performance_2_w)\n",
    "print(\"Linear Regression NLL on validation 2 weeks: \", val_performance_2_w)\n",
    "print(\"Linear Regression NLL on test 2 weeks: \", test_performance_2_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_linear_model(model_lr_2_w, plot_model=\"train\", plot_col=\"cases\", x=x_train_2_w, y=y_train_2_w,\n",
    "                  image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_2_w, plot_model=\"val\", plot_col=\"cases\", x=x_valid_2_w, y=y_valid_2_w,\n",
    "              image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_2_w, plot_model=\"test\", plot_col=\"cases\", x=x_test_2_w, y=y_test_2_w,\n",
    "              image_path=graphs_path + image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cpd(model_lr_2_w, 2, x_train_2_w, y_train_2_w)\n",
    "plot_cpd(model_lr_2_w, 2, x_valid_2_w, y_valid_2_w)\n",
    "plot_cpd(model_lr_2_w, 2, x_test_2_w, y_test_2_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=2  # Indica el salto entre la semana con datos y la semana a predecir: 1 indica un salto de 1 semana,\n",
    "         # por lo tanto, se hará una predicción de 2 semanas después\n",
    "data_train_3_w = np.array(df_train, dtype=np.float32)\n",
    "x_train_3_w = data_train_3_w[:-label_width-shift]\n",
    "y_train_3_w = np.squeeze(data_train_3_w[input_width+shift:])\n",
    "data_valid_3_w = np.array(df_valid, dtype=np.float32)\n",
    "x_valid_3_w = data_valid_3_w[:-label_width-shift]\n",
    "y_valid_3_w = np.squeeze(data_valid_3_w[input_width+shift:])\n",
    "data_test_3_w = np.array(df_test, dtype=np.float32)\n",
    "x_test_3_w = data_test_3_w[:-label_width-shift]\n",
    "y_test_3_w = np.squeeze(data_test_3_w[input_width+shift:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_3_w = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2),\n",
    "        tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[:, :1],\n",
    "                                                    scale=1e-3 + tf.math.softplus(0.05 * t[:, 1:]))),\n",
    "    ])\n",
    "model_lr_3_w.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=nll)\n",
    "result_lr_3_w = model_lr_3_w.fit(x_train_3_w, y_train_3_w, epochs=epochs, validation_data=(x_valid_3_w, y_valid_3_w), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_3_w.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_history(result_lr_3_w, 'Train history loss for ' + country + \" \" +\n",
    "                   datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\"), final_model_path + image_path)\n",
    "\n",
    "train_performance_3_w = model_lr_3_w.evaluate(x_train_3_w, y_train_3_w, verbose=1)\n",
    "val_performance_3_w = model_lr_3_w.evaluate(x_valid_3_w, y_valid_3_w, verbose=1)\n",
    "test_performance_3_w = model_lr_3_w.evaluate(x_test_3_w, y_test_3_w, verbose=1)\n",
    "print(\"Linear Regression NLL on training 3 weeks: \", train_performance_3_w)\n",
    "print(\"Linear Regression NLL on validation 3 weeks: \", val_performance_3_w)\n",
    "print(\"Linear Regression NLL on test 3 weeks: \", test_performance_3_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_linear_model(model_lr_3_w, plot_model=\"train\", plot_col=\"cases\", x=x_train_3_w, y=y_train_3_w,\n",
    "                  image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_3_w, plot_model=\"val\", plot_col=\"cases\", x=x_valid_3_w, y=y_valid_3_w,\n",
    "              image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_3_w, plot_model=\"test\", plot_col=\"cases\", x=x_test_3_w, y=y_test_3_w,\n",
    "              image_path=graphs_path + image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cpd(model_lr_3_w, 3, x_train_3_w, y_train_3_w)\n",
    "plot_cpd(model_lr_3_w, 3, x_valid_3_w, y_valid_3_w)\n",
    "plot_cpd(model_lr_3_w, 3, x_test_3_w, y_test_3_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=3  # Indica el salto entre la semana con datos y la semana a predecir: 1 indica un salto de 1 semana,\n",
    "         # por lo tanto, se hará una predicción de 2 semanas después\n",
    "data_train_4_w = np.array(df_train, dtype=np.float32)\n",
    "x_train_4_w = data_train_4_w[:-label_width-shift]\n",
    "y_train_4_w = np.squeeze(data_train_4_w[input_width+shift:])\n",
    "data_valid_4_w = np.array(df_valid, dtype=np.float32)\n",
    "x_valid_4_w = data_valid_4_w[:-label_width-shift]\n",
    "y_valid_4_w = np.squeeze(data_valid_4_w[input_width+shift:])\n",
    "data_test_4_w = np.array(df_test, dtype=np.float32)\n",
    "x_test_4_w = data_test_4_w[:-label_width-shift]\n",
    "y_test_4_w = np.squeeze(data_test_4_w[input_width+shift:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_4_w = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2),\n",
    "        tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[:, :1],\n",
    "                                                    scale=1e-3 + tf.math.softplus(0.05 * t[:, 1:]))),\n",
    "    ])\n",
    "model_lr_4_w.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=nll)\n",
    "result_lr_4_w = model_lr_4_w.fit(x_train_4_w, y_train_4_w, epochs=epochs, validation_data=(x_valid_4_w, y_valid_4_w), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lr_4_w.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_history(result_lr_4_w, 'Train history loss for ' + country + \" \" +\n",
    "                   datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\"), final_model_path + image_path)\n",
    "\n",
    "train_performance_4_w = model_lr_4_w.evaluate(x_train_4_w, y_train_4_w, verbose=1)\n",
    "val_performance_4_w = model_lr_4_w.evaluate(x_valid_4_w, y_valid_4_w, verbose=1)\n",
    "test_performance_4_w = model_lr_4_w.evaluate(x_test_4_w, y_test_4_w, verbose=1)\n",
    "print(\"Linear Regression NLL on training 4 weeks: \", train_performance_4_w)\n",
    "print(\"Linear Regression NLL on validation 4 weeks: \", val_performance_4_w)\n",
    "print(\"Linear Regression NLL on test 4 weeks: \", test_performance_4_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_linear_model(model_lr_4_w, plot_model=\"train\", plot_col=\"cases\", x=x_train_4_w, y=y_train_4_w,\n",
    "                  image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_4_w, plot_model=\"val\", plot_col=\"cases\", x=x_valid_4_w, y=y_valid_4_w,\n",
    "              image_path=graphs_path + image_path)\n",
    "plot_linear_model(model_lr_4_w, plot_model=\"test\", plot_col=\"cases\", x=x_test_4_w, y=y_test_4_w,\n",
    "              image_path=graphs_path + image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cpd(model_lr_4_w, 4, x_train_4_w, y_train_4_w)\n",
    "plot_cpd(model_lr_4_w, 4, x_valid_4_w, y_valid_4_w)\n",
    "plot_cpd(model_lr_4_w, 4, x_test_4_w, y_test_4_w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"SUMMARY:\\n\")\n",
    "print(\"Linear Regression NLL on test 1 week: \", test_performance_1_w)\n",
    "print(\"Linear Regression NLL on test 2 weeks: \", test_performance_2_w)\n",
    "print(\"Linear Regression NLL on test 3 weeks: \", test_performance_3_w)\n",
    "print(\"Linear Regression NLL on test 4 weeks: \", test_performance_4_w)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_forecasts_file(country, values, date_init, date_end, num_weeks, quantiles=[2.5, 25, 50, 75, 97.5], plot_col_index=0):\n",
    "    forecast_filename = processed_path + date_init + \"-\" + team_model_name + \".csv\"\n",
    "    if os.path.exists(forecast_filename):\n",
    "        append_write = 'a'  # append if already exists\n",
    "    else:\n",
    "        append_write = 'w'  # make a new file if not\n",
    "\n",
    "    with open(forecast_filename, append_write) as file:\n",
    "        if append_write == \"w\":\n",
    "            file.write(\"scenario_id,forecast_date,target,target_end_date,location,type,quantile,value\\n\")\n",
    "        for i in range(len(values)):\n",
    "            file.write(\"forecast,\")\n",
    "            file.write(date_init + \",\")\n",
    "            file.write(str(num_weeks) + \" wk ahead inc case,\")\n",
    "            file.write(date_end + \",\")\n",
    "            file.write(country_codes[country] + \",\")\n",
    "            if i == 0:\n",
    "                file.write(\"point,NA,\")\n",
    "                if values[median_quantile_index] < 0:\n",
    "                    file.write(str(-values[median_quantile_index]) + \"\\n\")\n",
    "                else:\n",
    "                    file.write(str(values[median_quantile_index]) + \"\\n\")\n",
    "                if len(values) > 1:\n",
    "                    file.write(\"forecast,\")\n",
    "                    file.write(date_init + \",\")\n",
    "                    file.write(str(num_weeks) + \" wk ahead inc case,\")\n",
    "                    file.write(date_end + \",\")\n",
    "                    file.write(country_codes[country] + \",\")\n",
    "                    file.write(\"quantile,\")\n",
    "                    file.write(str(quantiles[i] / 100.00) + \",\")\n",
    "                    if values[i] < 0:\n",
    "                        file.write(str(-values[i]) + \"\\n\")\n",
    "                    else:\n",
    "                        file.write(str(values[i]) + \"\\n\")\n",
    "            else:\n",
    "                file.write(\"quantile,\")\n",
    "                file.write(str(quantiles[i] / 100.00) + \",\")\n",
    "                if values[i] < 0:\n",
    "                    file.write(str(-values[i]) + \"\\n\")\n",
    "                else:\n",
    "                    file.write(str(values[i]) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generamos predicciones y los cuantiles para poder comparar con los modelos del Hub\n",
    "y_hat_1_w = model_lr_1_w(x_test_1_w)\n",
    "post_quantile_1_w = np.percentile(y_hat_1_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_2_w = model_lr_2_w(x_test_2_w)\n",
    "post_quantile_2_w = np.percentile(y_hat_2_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_3_w = model_lr_3_w(x_test_3_w)\n",
    "post_quantile_3_w = np.percentile(y_hat_3_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_4_w = model_lr_4_w(x_test_4_w)\n",
    "post_quantile_4_w = np.percentile(y_hat_4_w.mean(), quantiles, interpolation=\"midpoint\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_forecasts_file(country=country, values=post_quantile_1_w, date_init=\"2021-08-02\", date_end=\"2021-08-07\",\n",
    "                      num_weeks=1, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_2_w, date_init=\"2021-08-02\", date_end=\"2021-08-14\",\n",
    "                      num_weeks=2, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_3_w, date_init=\"2021-08-02\", date_end=\"2021-08-21\",\n",
    "                      num_weeks=3, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_4_w, date_init=\"2021-08-02\", date_end=\"2021-08-28\",\n",
    "                      num_weeks=4, quantiles=quantiles, plot_col_index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_day = \"2021-08-07\"\n",
    "df = read_truth_data(data_path + \"truth_JHU-Incident Cases.csv\",\n",
    "                     data_path + \"truth_JHU-Incident Deaths.csv\", country=country, period=period, last_day=last_day)\n",
    "df_test = df[-int(len(df) * (test_data_pcnt / 100)):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=0\n",
    "data_test = np.array(df_test, dtype=np.float32)\n",
    "x_test_1_w = data_test[:-label_width-shift]\n",
    "shift=1\n",
    "x_test_2_w = data_test[:-label_width-shift]\n",
    "shift=2\n",
    "x_test_3_w = data_test[:-label_width-shift]\n",
    "shift=3\n",
    "x_test_4_w = data_test[:-label_width-shift]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generamos predicciones y los cuantiles para poder comparar con los modelos del Hub\n",
    "y_hat_1_w = model_lr_1_w(x_test_1_w)\n",
    "post_quantile_1_w = np.percentile(y_hat_1_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_2_w = model_lr_2_w(x_test_2_w)\n",
    "post_quantile_2_w = np.percentile(y_hat_2_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_3_w = model_lr_3_w(x_test_3_w)\n",
    "post_quantile_3_w = np.percentile(y_hat_3_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_4_w = model_lr_4_w(x_test_4_w)\n",
    "post_quantile_4_w = np.percentile(y_hat_4_w.mean(), quantiles, interpolation=\"midpoint\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_forecasts_file(country=country, values=post_quantile_1_w, date_init=\"2021-08-09\", date_end=\"2021-08-14\",\n",
    "                      num_weeks=1, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_2_w, date_init=\"2021-08-09\", date_end=\"2021-08-21\",\n",
    "                      num_weeks=2, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_3_w, date_init=\"2021-08-09\", date_end=\"2021-08-28\",\n",
    "                      num_weeks=3, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_4_w, date_init=\"2021-08-09\", date_end=\"2021-09-04\",\n",
    "                      num_weeks=4, quantiles=quantiles, plot_col_index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_day = \"2021-08-14\"\n",
    "df = read_truth_data(data_path + \"truth_JHU-Incident Cases.csv\",\n",
    "                     data_path + \"truth_JHU-Incident Deaths.csv\", country=country, period=period, last_day=last_day)\n",
    "df_test = df[-int(len(df) * (test_data_pcnt / 100)):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=0\n",
    "data_test = np.array(df_test, dtype=np.float32)\n",
    "x_test_1_w = data_test[:-label_width-shift]\n",
    "shift=1\n",
    "x_test_2_w = data_test[:-label_width-shift]\n",
    "shift=2\n",
    "x_test_3_w = data_test[:-label_width-shift]\n",
    "shift=3\n",
    "x_test_4_w = data_test[:-label_width-shift]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generamos predicciones y los cuantiles para poder comparar con los modelos del Hub\n",
    "y_hat_1_w = model_lr_1_w(x_test_1_w)\n",
    "post_quantile_1_w = np.percentile(y_hat_1_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_2_w = model_lr_2_w(x_test_2_w)\n",
    "post_quantile_2_w = np.percentile(y_hat_2_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_3_w = model_lr_3_w(x_test_3_w)\n",
    "post_quantile_3_w = np.percentile(y_hat_3_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_4_w = model_lr_4_w(x_test_4_w)\n",
    "post_quantile_4_w = np.percentile(y_hat_4_w.mean(), quantiles, interpolation=\"midpoint\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_forecasts_file(country=country, values=post_quantile_1_w, date_init=\"2021-08-16\", date_end=\"2021-08-21\",\n",
    "                      num_weeks=1, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_2_w, date_init=\"2021-08-16\", date_end=\"2021-08-28\",\n",
    "                      num_weeks=2, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_3_w, date_init=\"2021-08-16\", date_end=\"2021-09-04\",\n",
    "                      num_weeks=3, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_4_w, date_init=\"2021-08-16\", date_end=\"2021-09-11\",\n",
    "                      num_weeks=4, quantiles=quantiles, plot_col_index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_day = \"2021-08-21\"\n",
    "df = read_truth_data(data_path + \"truth_JHU-Incident Cases.csv\",\n",
    "                     data_path + \"truth_JHU-Incident Deaths.csv\", country=country, period=period, last_day=last_day)\n",
    "df_test = df[-int(len(df) * (test_data_pcnt / 100)):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=0\n",
    "data_test = np.array(df_test, dtype=np.float32)\n",
    "x_test_1_w = data_test[:-label_width-shift]\n",
    "shift=1\n",
    "x_test_2_w = data_test[:-label_width-shift]\n",
    "shift=2\n",
    "x_test_3_w = data_test[:-label_width-shift]\n",
    "shift=3\n",
    "x_test_4_w = data_test[:-label_width-shift]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generamos predicciones y los cuantiles para poder comparar con los modelos del Hub\n",
    "y_hat_1_w = model_lr_1_w(x_test_1_w)\n",
    "post_quantile_1_w = np.percentile(y_hat_1_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_2_w = model_lr_2_w(x_test_2_w)\n",
    "post_quantile_2_w = np.percentile(y_hat_2_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_3_w = model_lr_3_w(x_test_3_w)\n",
    "post_quantile_3_w = np.percentile(y_hat_3_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_4_w = model_lr_4_w(x_test_4_w)\n",
    "post_quantile_4_w = np.percentile(y_hat_4_w.mean(), quantiles, interpolation=\"midpoint\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_forecasts_file(country=country, values=post_quantile_1_w, date_init=\"2021-08-23\", date_end=\"2021-08-28\",\n",
    "                      num_weeks=1, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_2_w, date_init=\"2021-08-23\", date_end=\"2021-09-04\",\n",
    "                      num_weeks=2, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_3_w, date_init=\"2021-08-23\", date_end=\"2021-09-11\",\n",
    "                      num_weeks=3, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_4_w, date_init=\"2021-08-23\", date_end=\"2021-09-18\",\n",
    "                      num_weeks=4, quantiles=quantiles, plot_col_index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_day = \"2021-08-28\"\n",
    "df = read_truth_data(data_path + \"truth_JHU-Incident Cases.csv\",\n",
    "                     data_path + \"truth_JHU-Incident Deaths.csv\", country=country, period=period, last_day=last_day)\n",
    "df_test = df[-int(len(df) * (test_data_pcnt / 100)):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shift=0\n",
    "data_test = np.array(df_test, dtype=np.float32)\n",
    "x_test_1_w = data_test[:-label_width-shift]\n",
    "shift=1\n",
    "x_test_2_w = data_test[:-label_width-shift]\n",
    "shift=2\n",
    "x_test_3_w = data_test[:-label_width-shift]\n",
    "shift=3\n",
    "x_test_4_w = data_test[:-label_width-shift]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generamos predicciones y los cuantiles para poder comparar con los modelos del Hub\n",
    "y_hat_1_w = model_lr_1_w(x_test_1_w)\n",
    "post_quantile_1_w = np.percentile(y_hat_1_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_2_w = model_lr_2_w(x_test_2_w)\n",
    "post_quantile_2_w = np.percentile(y_hat_2_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_3_w = model_lr_3_w(x_test_3_w)\n",
    "post_quantile_3_w = np.percentile(y_hat_3_w.mean(), quantiles, interpolation=\"midpoint\")\n",
    "y_hat_4_w = model_lr_4_w(x_test_4_w)\n",
    "post_quantile_4_w = np.percentile(y_hat_4_w.mean(), quantiles, interpolation=\"midpoint\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_forecasts_file(country=country, values=post_quantile_1_w, date_init=\"2021-08-30\", date_end=\"2021-09-04\",\n",
    "                      num_weeks=1, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_2_w, date_init=\"2021-08-30\", date_end=\"2021-09-11\",\n",
    "                      num_weeks=2, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_3_w, date_init=\"2021-08-30\", date_end=\"2021-09-18\",\n",
    "                      num_weeks=3, quantiles=quantiles, plot_col_index=0)\n",
    "create_forecasts_file(country=country, values=post_quantile_4_w, date_init=\"2021-08-30\", date_end=\"2021-09-25\",\n",
    "                      num_weeks=4, quantiles=quantiles, plot_col_index=0)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}